{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xqB5XvP-U3Sn",
        "L21RLrfDFdcE",
        "pD8XJufeSDAm",
        "BCSPjj-D4Fao",
        "veJ5zQOxSqPJ",
        "YIqsDew7Yn1o",
        "GPKvcwXX4KDe",
        "IZhGKvIO0FKu",
        "Vx9r4CJg2xkY",
        "r-sEJmKq6msb",
        "7JGm1YhnUExE",
        "gCymNXQuW15K",
        "D6O8akfmUoWc",
        "rkazD35dv0Un",
        "V4qRVZ9Jv2NV",
        "QRgW9szKv46I",
        "15juxBrzgiLk",
        "UJL5drQCU3TO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adigew/MLOps/blob/main/AI_Vertex_Pipeline1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqB5XvP-U3Sn"
      },
      "source": [
        "# Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UmtuvhYixkz"
      },
      "source": [
        "# updated to the latest dependencies on November 2022\n",
        "!pip install google-cloud-aiplatform==1.19.0 --upgrade\n",
        "!pip install google-cloud-pipeline-components==1.0.27 --upgrade\n",
        "!pip install kfp==1.8.16 --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtTT_nZzevNK"
      },
      "source": [
        "pip install -U google-cloud-aiplatform \"shapely<2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJyao5kfylbI"
      },
      "source": [
        "**Please restart your Colab runtime before importing the modules**\n",
        "\n",
        "Otherwise you might get a version conflict related error. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mcs7B5VUox_"
      },
      "source": [
        "import kfp\n",
        "\n",
        "from typing import NamedTuple\n",
        "\n",
        "from kfp.v2.dsl import pipeline\n",
        "from kfp.v2.dsl import component\n",
        "from kfp.v2.dsl import OutputPath\n",
        "from kfp.v2.dsl import InputPath\n",
        "\n",
        "from kfp.v2.dsl import Output\n",
        "from kfp.v2.dsl import Metrics\n",
        "\n",
        "from kfp.v2 import compiler\n",
        "from kfp.v2.google.client import AIPlatformClient\n",
        "\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform import pipeline_jobs\n",
        "\n",
        "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
        "\n",
        "from google_cloud_pipeline_components.v1.model import ModelUploadOp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L21RLrfDFdcE"
      },
      "source": [
        "# Authentication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0RNBXMlf3Gl"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "credentials = auth._check_adc()\n",
        "print(credentials)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGReMEivS070"
      },
      "source": [
        "set the project id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYz_UaJ1S0QX"
      },
      "source": [
        "PROJECT_ID = \"statmike-demo3-374213\"\n",
        "PIPELINE_ROOT = \"gs://ml-demo-bites/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD8XJufeSDAm"
      },
      "source": [
        "# Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v5AkYzaFb3Q"
      },
      "source": [
        "# use this instead\n",
        "aiplatform.init(project=PROJECT_ID,\n",
        "                location='us-central1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCSPjj-D4Fao"
      },
      "source": [
        "# Pipeline Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gyZkv8xyenN"
      },
      "source": [
        "## Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onddQwd1U1qR"
      },
      "source": [
        "@component() \n",
        "def concat(a: str, b: str) -> str:\n",
        "  return a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma7xWwLLVSlr"
      },
      "source": [
        "@component\n",
        "def reverse(a: str)->NamedTuple(\"outputs\", [(\"before\", str), (\"after\", str)]):\n",
        "  return a, a[::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZxMEEIWygAg"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUrZade1VZGy"
      },
      "source": [
        "@pipeline(name=\"basic-pipeline\",\n",
        "          pipeline_root=PIPELINE_ROOT + \"basic-pipeline\")\n",
        "def basic_pipeline(a: str='stres', b: str='sed'):\n",
        "    concat_task = concat(a, b)\n",
        "    reverse_task = reverse(concat_task.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTL5tzhSXRpG"
      },
      "source": [
        "## Compile\n",
        "\n",
        "The compiler takes our pipeline function and compiles it into our pipeline specifiction as json file. This json file we can use to create our pipeline in Vertex AI Pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF0r0-CwVgpF"
      },
      "source": [
        "compiler.Compiler().compile(\n",
        "pipeline_func=basic_pipeline, package_path=\"basic_pipeline.json\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4_93MkF369u"
      },
      "source": [
        "## Run\n",
        "\n",
        "Create the run job using the API. \n",
        "You can also directly upload the pipeline JSON file in the Vertx AI UI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwlXs0reY56x"
      },
      "source": [
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"basic-pipeline\",\n",
        "    template_path=\"basic_pipeline.json\",\n",
        "    parameter_values={\"a\": \"stres\", \"b\": \"sed\"}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aogrQzmBZs7T"
      },
      "source": [
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veJ5zQOxSqPJ"
      },
      "source": [
        "## Component Specification (function based component)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1zyzD1-Ssi2"
      },
      "source": [
        "@component(output_component_file=\"concat_component.yaml\") \n",
        "def concat(a: str, b: str) -> str:\n",
        "  return a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzHM-vQ2T82E"
      },
      "source": [
        "!cat ./concat_component.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIqsDew7Yn1o"
      },
      "source": [
        "## Share components\n",
        "In this example we use the component specification created based on a function based component."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW-PsUmPYuFo"
      },
      "source": [
        "@pipeline(name=\"share-component\", \n",
        "          pipeline_root=PIPELINE_ROOT + \"share-component-pipeine\")\n",
        "def share_component_pipeline(a: str='stres', b: str='sed'):\n",
        "    #concat_op = concat(a, b)\n",
        "    concat_component = kfp.components.load_component_from_file('./concat_component.yaml')\n",
        "\n",
        "    concat_task = concat_component(a,b)\n",
        "    reverse_task = reverse(concat_task.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmW81e_WZ1mZ"
      },
      "source": [
        "# just the usual boilerplate code to run the pipeline\n",
        "compiler.Compiler().compile(\n",
        "  pipeline_func=share_component_pipeline, package_path=\"share_component_pipeline.json\"\n",
        ")\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"share-component-pipeline\",\n",
        "    template_path=\"share_component_pipeline.json\",\n",
        "    parameter_values={\"a\": \"stres\", \"b\": \"sed\"}\n",
        ")\n",
        "\n",
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPKvcwXX4KDe"
      },
      "source": [
        "## Pipeline with GPU and machine type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxntLJgD4l45"
      },
      "source": [
        "The following is an example how you can add an GPU to your component. For example the training componentn that needs access to accelerators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v231zyV4MUO"
      },
      "source": [
        "@component(output_component_file=\"gpu_training.yaml\", \n",
        "           base_image=\"gcr.io/deeplearning-platform-release/tf2-gpu.2-6\") \n",
        "def gpuTrainingFunc() -> bool:\n",
        "  import logging\n",
        "  import tensorflow as tf\n",
        "\n",
        "  gpus = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "  for gpu in gpus:\n",
        "    logging.info('Name: {} Type: {}'.format(gpu.name, gpu.device_type))\n",
        "  \n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN_qYZE-6Nfn"
      },
      "source": [
        "@pipeline(name=\"gpu-pipeline\",\n",
        "          pipeline_root=PIPELINE_ROOT + \"gpu-pipeline\")\n",
        "def gpu_pipeline():\n",
        "    gpuTraining = gpuTrainingFunc().add_node_selector_constraint(\n",
        "        label_name=\"cloud.google.com/gke-accelerator\", \n",
        "        value=\"NVIDIA_TESLA_A100\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRXVqzdi7rdD"
      },
      "source": [
        "compiler.Compiler().compile(\n",
        "  pipeline_func=gpu_pipeline, package_path=\"gpu_pipeline.json\"\n",
        ")\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(\n",
        "   display_name=\"gpu-pipeline\",\n",
        "   template_path=\"gpu_pipeline.json\"\n",
        ")\n",
        "\n",
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZhGKvIO0FKu"
      },
      "source": [
        "## Schedule \n",
        "switch over to GCP and check your Cloud Functions and Cloud Scheduler ;)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deprecated don't use this anymore\n",
        "from kfp.v2.google.client import AIPlatformClient\n",
        "api_client = AIPlatformClient(project_id=PROJECT_ID,\n",
        "                              region='us-central1')\n"
      ],
      "metadata": {
        "id": "l3OvzW_e0bBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YtB-uUp0ILg"
      },
      "source": [
        "from kfp.v2.google.client import AIPlatformClient\n",
        "api_client = AIPlatformClient(project_id=PROJECT_ID, region='us-central1')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVVt4S130Vrz"
      },
      "source": [
        "api_client.create_schedule_from_job_spec(\n",
        "    job_spec_path='basic_pipeline.json',\n",
        "    schedule='*/10 * * * *' # every 10 minutes\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx9r4CJg2xkY"
      },
      "source": [
        "## Additional Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al_sL-1f2zYK"
      },
      "source": [
        "@component(packages_to_install = [\"pandas==1.3.4\"],) \n",
        "def additional_packages():\n",
        "  import pandas\n",
        "  print(pandas.__version__)\n",
        "\n",
        "# fails for demonstration purposes\n",
        "@component() \n",
        "def additional_packages_missing():\n",
        "  import pandas\n",
        "  print(pandas.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJl27Itt3iCw"
      },
      "source": [
        "@pipeline(name=\"additional-packages-pipeline\",\n",
        "          pipeline_root=PIPELINE_ROOT + \"additional-packages-pipeline\")\n",
        "def additional_packges_pipeline():\n",
        "    additional_packages_task = additional_packages()\n",
        "    additional_packages_missing_task = additional_packages_missing()\n",
        "\n",
        "compiler.Compiler().compile(\n",
        "  pipeline_func=additional_packges_pipeline, package_path=\"additional_packages_pipeline.json\"\n",
        ")\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"additional-packages-pipeline\",\n",
        "    template_path=\"additional_packages_pipeline.json\"\n",
        ")\n",
        "\n",
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-sEJmKq6msb"
      },
      "source": [
        "## Base Image\n",
        "\n",
        "Compare the component specification yaml and find the difference\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/training/pre-built-containers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ1P8F826sjO"
      },
      "source": [
        "@component(output_component_file=\"custom_base_image_component.yaml\",\n",
        "           base_image=\"gcr.io/deeplearning-platform-release/tf2-gpu.2-6\"\n",
        ") \n",
        "def custom_base_image():\n",
        "  import tensorflow as tf\n",
        "  print(tf.version.VERSION)\n",
        "\n",
        "# fails for demonstration purposes\n",
        "@component(output_component_file=\"default_base_image_component.yaml\") \n",
        "def default_base_image():\n",
        "  import tensorflow as tf\n",
        "  print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOnGZ59z64Y_"
      },
      "source": [
        "!cat ./default_base_image_component.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9EgmAoq7DAa"
      },
      "source": [
        "!cat ./custom_base_image_component.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JGm1YhnUExE"
      },
      "source": [
        "## Predefined Components\n",
        "\n",
        "For a full list of pre-defined components see https://cloud.google.com/vertex-ai/docs/pipelines/gcpc-list\n",
        "\n",
        "Predefined components depends on the use case.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckZCJavxBtf7"
      },
      "source": [
        "# Pipeline end to end (XGBoost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCymNXQuW15K"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLJqZSzYBu2y"
      },
      "source": [
        "from typing import NamedTuple\n",
        "\n",
        "from kfp.v2 import dsl\n",
        "from kfp.v2.dsl import (Artifact,\n",
        "                        Dataset,\n",
        "                        Input,\n",
        "                        Model,\n",
        "                        Output,\n",
        "                        Metrics,\n",
        "                        ClassificationMetrics,\n",
        "                        component, \n",
        "                        Markdown)\n",
        "\n",
        "from kfp.v2 import compiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6O8akfmUoWc"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPKVVep2BxU9"
      },
      "source": [
        "@component(\n",
        "    packages_to_install = [\n",
        "        \"pandas==1.3.4\",\n",
        "        \"scikit-learn==1.0.1\",\n",
        "    ],\n",
        ")\n",
        "def get_data(\n",
        "    dataset_train: Output[Dataset],\n",
        "    dataset_test: Output[Dataset],\n",
        "):\n",
        "    \n",
        "    from sklearn import datasets\n",
        "    from sklearn.model_selection import train_test_split as tts\n",
        "    import pandas as pd\n",
        "\n",
        "\n",
        "    # dataset https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
        "    data_raw = datasets.load_breast_cancer()\n",
        "    data = pd.DataFrame(data_raw.data, columns=data_raw.feature_names)\n",
        "    data[\"target\"] = data_raw.target\n",
        "    \n",
        "    train, test = tts(data, test_size=0.3)\n",
        "    \n",
        "    train.to_csv(dataset_train.path)\n",
        "    test.to_csv(dataset_test.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmllUUq0UqDo"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aVHg2lSByxy"
      },
      "source": [
        "@component(\n",
        "    packages_to_install = [\n",
        "        \"pandas==1.3.4\",\n",
        "        \"xgboost==1.5.1\",\n",
        "        \"scikit-learn==1.0.1\", #xgboost requires scikitlearn\n",
        "    ],\n",
        ")\n",
        "def train_model(\n",
        "    dataset: Input[Dataset],\n",
        "    model_artifact: Output[Model]\n",
        "):\n",
        "    \n",
        "    from xgboost import XGBClassifier\n",
        "    import pandas as pd\n",
        "    import pickle\n",
        "    \n",
        "    #model_artifact = 'model.bst'\n",
        "    data = pd.read_csv(dataset.path)\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        objective=\"binary:logistic\"\n",
        "    )\n",
        "    model.fit(\n",
        "        data.drop(columns=[\"target\"]),\n",
        "        data.target,\n",
        "    )\n",
        "    with open('model.pkl', 'wb') as model_file: \n",
        "      pickle.dump(model, model_file)\n",
        "\n",
        "    score = model.score(\n",
        "        data.drop(columns=[\"target\"]),\n",
        "        data.target,\n",
        "    )\n",
        "\n",
        "    model_artifact.metadata[\"train_score\"] = float(score)\n",
        "    model_artifact.metadata[\"framework\"] = \"XGBoost\"\n",
        "\n",
        "    print(model_artifact.path)\n",
        "    \n",
        "    model.save_model(model_artifact.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkazD35dv0Un"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1AiObLIB1cx"
      },
      "source": [
        "@component(\n",
        "    packages_to_install = [\n",
        "        \"pandas==1.3.4\",\n",
        "        \"scikit-learn==1.0.1\",\n",
        "        \"xgboost==1.5.1\"\n",
        "    ],\n",
        ")\n",
        "def eval_model(\n",
        "    test_set: Input[Dataset],\n",
        "    xgb_model: Input[Model],\n",
        "    metrics: Output[ClassificationMetrics],\n",
        "    smetrics: Output[Metrics]\n",
        ") -> NamedTuple(\"Outputs\", [(\"deploy\", str)]): \n",
        "    from xgboost import XGBClassifier\n",
        "    import pandas as pd\n",
        "    \n",
        "    data = pd.read_csv(test_set.path)\n",
        "    model = XGBClassifier()\n",
        "    model.load_model(xgb_model.path)\n",
        "    \n",
        "    score = model.score(\n",
        "        data.drop(columns=[\"target\"]),\n",
        "        data.target,\n",
        "    )\n",
        "    \n",
        "    from sklearn.metrics import roc_curve\n",
        "    y_scores =  model.predict_proba(data.drop(columns=[\"target\"]))[:, 1]\n",
        "    fpr, tpr, thresholds = roc_curve(\n",
        "         y_true=data.target.to_numpy(), y_score=y_scores, pos_label=True\n",
        "    )\n",
        "    metrics.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\n",
        "    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    y_pred = model.predict(data.drop(columns=[\"target\"]))\n",
        "    \n",
        "    metrics.log_confusion_matrix(\n",
        "       [\"False\", \"True\"],\n",
        "       confusion_matrix(\n",
        "           data.target, y_pred\n",
        "       ).tolist()\n",
        "    )\n",
        "    \n",
        "    xgb_model.metadata[\"test_score\"] = float(score)\n",
        "    smetrics.log_metric(\"score\", float(score))\n",
        "\n",
        "\n",
        "    deploy = \"true\"\n",
        "    #compare threshold or to previous\n",
        "\n",
        "    return (deploy,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4qRVZ9Jv2NV"
      },
      "source": [
        "## Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZq-EaJngwFW"
      },
      "source": [
        "@component(packages_to_install=[\"google-cloud-aiplatform==1.3.0\"])\n",
        "def deploy(\n",
        "    model: Input[Model],\n",
        "    project: str,\n",
        "    region: str,):\n",
        "  \n",
        "  import logging\n",
        "  from google.cloud import aiplatform\n",
        "  aiplatform.init(project=project, location=region)\n",
        "\n",
        "  logging.basicConfig(level=logging.DEBUG)\n",
        "  logging.debug(model)\n",
        "\n",
        "  print(model)\n",
        "  print(model.uri)\n",
        "\n",
        "  import os\n",
        "  path,file = os.path.split(model.uri)\n",
        "\n",
        "  import datetime\n",
        "  \n",
        "  # datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "  # serving image https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers#xgboost\n",
        "  deployed_model = aiplatform.Model.upload(\n",
        "        display_name=\"xgboost-pipeline\",\n",
        "        artifact_uri = path,\n",
        "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-4:latest\"\n",
        "  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgW9szKv46I"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8JS0BA0B7za"
      },
      "source": [
        "@dsl.pipeline(\n",
        "    # Default pipeline root. You can override it when submitting the pipeline.\n",
        "    pipeline_root=PIPELINE_ROOT + \"xgboost-pipeline\",\n",
        "    # A name for the pipeline. Use to determine the pipeline Context.\n",
        "    name=\"xgboost-pipeline-with-deployment\",\n",
        ")\n",
        "def pipeline():\n",
        "    dataset_op = get_data()\n",
        "    training_op = train_model(dataset_op.outputs[\"dataset_train\"])\n",
        "    eval_op = eval_model(\n",
        "        test_set=dataset_op.outputs[\"dataset_test\"],\n",
        "        xgb_model=training_op.outputs[\"model_artifact\"]\n",
        "        \n",
        "    )\n",
        "\n",
        "    with dsl.Condition(\n",
        "        eval_op.outputs[\"deploy\"] == \"true\",\n",
        "        name=\"deploy\",\n",
        "    ):\n",
        "\n",
        "      deploy_op = deploy(training_op.outputs[\"model_artifact\"], \n",
        "                         'statmike-demo3-374213',\n",
        "                         'us-central1')\n",
        "\n",
        "    # we need a solution for xgb models\n",
        "    # its here https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api#aiplatform_deploy_model_custom_trained_model_sample-python\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15juxBrzgiLk"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfz5joUmghwp"
      },
      "source": [
        "compiler.Compiler().compile(\n",
        "    pipeline_func=pipeline,\n",
        "    package_path='xgb_pipeline.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS2DvPDSB_FG"
      },
      "source": [
        "response = api_client.create_run_from_job_spec(\n",
        "    'xgb_pipeline.json',\n",
        "    enable_caching=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSDY3Rrh8OTq"
      },
      "source": [
        "## Run Pipeline (new)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g0qJwcG8QHK"
      },
      "source": [
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"xgb-pipeline\",\n",
        "    template_path=\"xgb_pipeline.json\"\n",
        ")\n",
        "\n",
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "31_R3lA-bxNq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}